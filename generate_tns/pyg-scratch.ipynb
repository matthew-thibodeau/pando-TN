{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61093400-228f-4a8c-9dff-fb76cb38f9e9",
   "metadata": {},
   "source": [
    "## Pytorch-Geometric examples relavent to the ML-for-TN project\n",
    "\n",
    "Note: torch and torch-geometric (a.k.a. pyg) should be installed separately (NS's experience.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2c8541-329e-47e1-ab60-c6b050203185",
   "metadata": {},
   "source": [
    "Messing around with examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a95553c9-eb29-456f-a3de-0ca8b2b09832",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %automagic\n",
    "\n",
    "import torch\n",
    "from torch_geometric.data import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aff803f5-36f9-4be2-b755-d8c092c49fbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[3, 1], edge_index=[2, 4])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "** Node features\n",
      "tensor([[-1.],\n",
      "        [ 0.],\n",
      "        [ 1.]])\n",
      "\n",
      "** Edge indices\n",
      "tensor([[0, 1, 1, 2],\n",
      "        [1, 0, 2, 1]])\n",
      "\n",
      "** Edge features\n",
      "None\n",
      "\n",
      "** Target to train against\n",
      "None\n",
      "\n",
      "<class 'torch_geometric.data.data.Data'>\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Parameters:\n",
    "data.x: Node feature matrix with shape [num_nodes, num_node_features]\n",
    "data.edge_index: Graph connectivity in COO format with shape [2, num_edges] and type torch.long\n",
    "data.edge_attr: Edge feature matrix with shape [num_edges, num_edge_features]\n",
    "data.y: Target to train against (may have arbitrary shape), e.g., node-level targets of shape [num_nodes, *] or graph-level targets of shape [1, *]\n",
    "data.pos: Node position matrix with shape [num_nodes, num_dimensions]\n",
    "'''\n",
    "\n",
    "edge_index = torch.tensor([[0, 1, 1, 2],\n",
    "                           [1, 0, 2, 1]], dtype=torch.long)\n",
    "x = torch.tensor([[-1], [0], [1]], dtype=torch.float)\n",
    "\n",
    "data = Data(x=x, edge_index=edge_index)\n",
    "\n",
    "# Data(edge_index=[2, 4], x=[3, 1])\n",
    "display(data)\n",
    "dir(data)\n",
    "\n",
    "print(\"\\n** Node features\")\n",
    "print(data.x)\n",
    "print(\"\\n** Edge indices\")\n",
    "print(data.edge_index)\n",
    "print(\"\\n** Edge features\")\n",
    "print(data.edge_attr)\n",
    "print(\"\\n** Target to train against\")\n",
    "print(data.y)\n",
    "print()\n",
    "print(type(data))\n",
    "print(type(data.x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8d4863c4-d32e-4d34-ade3-422be74ce98c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys\n",
      "['edge_index', 'x']\n",
      "data['x']\n",
      "tensor([[-1.],\n",
      "        [ 0.],\n",
      "        [ 1.]])\n",
      "x found in data: \n",
      " item tensor([[-1.],\n",
      "        [ 0.],\n",
      "        [ 1.]])\n",
      "edge_index found in data: \n",
      " item tensor([[0, 1, 1, 2],\n",
      "        [1, 0, 2, 1]])\n",
      "Other command results:\n",
      "False\n",
      "3\n",
      "4\n",
      "1\n",
      "False\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# Validate data (make sure no issues, e.g. edge indices out of bounds)\n",
    "data.validate(raise_on_error=True)\n",
    "print(\"Keys\")\n",
    "print(data.keys())\n",
    "print(\"data['x']\")\n",
    "print(data['x'])\n",
    "for key, item in data:\n",
    "    print(f'{key} found in data: \\n item {item}')\n",
    "\n",
    "print(\"Other command results:\")\n",
    "print('edge_attr' in data)\n",
    "print(data.num_nodes)\n",
    "print(data.num_edges)\n",
    "print(data.num_node_features)\n",
    "print(data.has_isolated_nodes())\n",
    "print(data.has_self_loops())\n",
    "print(data.is_directed())\n",
    "\n",
    "# # Transfer data object to GPU.\n",
    "# Fails on my laptop, of course. NO GPU. Also, installation did not use GPU\n",
    "# device = torch.device('cuda')\n",
    "# data = data.to(device)\n",
    "\n",
    "# Using CPU instead\n",
    "device = torch.device('cpu')\n",
    "data = data.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7c11368f-1cb4-4bbb-81dd-1183feebf84d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENZYMES(600)\n",
      "600\n",
      "6\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "# Take in the ENZYME dataset from the example\n",
    "from torch_geometric.datasets import TUDataset\n",
    "\n",
    "dataset = TUDataset(root='/tmp/ENZYMES', name='ENZYMES')\n",
    "print(dataset)\n",
    "\n",
    "print( len(dataset) )\n",
    "print( dataset.num_classes )  # Classification task\n",
    "print( dataset.num_node_features )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8ad7aa22-0f5e-445e-ba7a-4f2941b59802",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(edge_index=[2, 168], x=[37, 3], y=[1])\n",
      "True\n",
      "tensor([[1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.]])\n",
      "tensor([5])\n",
      "tensor([[ 0,  0,  0,  1,  1,  1,  1,  1,  2,  2,  2,  2,  2,  3,  3,  3,  3,  3,\n",
      "          3,  4,  4,  4,  4,  5,  5,  5,  5,  5,  6,  6,  6,  6,  7,  7,  7,  7,\n",
      "          7,  8,  8,  8,  9,  9,  9,  9,  9, 10, 10, 10, 10, 11, 11, 11, 11, 12,\n",
      "         12, 12, 12, 12, 13, 13, 13, 13, 14, 14, 14, 14, 15, 15, 15, 15, 16, 16,\n",
      "         16, 16, 17, 17, 17, 17, 18, 18, 18, 19, 19, 19, 20, 20, 20, 20, 20, 20,\n",
      "         21, 21, 21, 21, 21, 22, 22, 22, 22, 23, 23, 23, 23, 24, 24, 24, 24, 25,\n",
      "         25, 25, 25, 25, 26, 26, 26, 26, 26, 27, 27, 27, 27, 27, 28, 28, 28, 28,\n",
      "         28, 28, 29, 29, 29, 29, 29, 29, 29, 30, 30, 30, 30, 30, 31, 31, 31, 32,\n",
      "         32, 32, 32, 33, 33, 33, 33, 33, 33, 34, 34, 34, 34, 34, 34, 35, 35, 35,\n",
      "         35, 35, 36, 36, 36, 36],\n",
      "        [ 1,  2,  3,  0,  2,  3, 24, 27,  0,  1,  3, 27, 28,  0,  1,  2,  4,  5,\n",
      "         28,  3,  5,  6, 29,  3,  4,  6,  7, 29,  4,  5,  7,  8,  5,  6,  8,  9,\n",
      "         10,  6,  7,  9,  7,  8, 10, 11, 12,  7,  9, 11, 12,  9, 10, 12, 26,  9,\n",
      "         10, 11, 25, 26, 14, 15, 16, 25, 13, 15, 16, 25, 13, 14, 16, 17, 13, 14,\n",
      "         15, 17, 15, 16, 18, 19, 17, 19, 20, 17, 18, 20, 18, 19, 21, 22, 23, 30,\n",
      "         20, 22, 23, 30, 35, 20, 21, 23, 35, 20, 21, 22, 33,  1, 27, 28, 29, 12,\n",
      "         13, 14, 26, 29, 11, 12, 25, 28, 29,  1,  2, 24, 28, 29,  2,  3, 24, 26,\n",
      "         27, 29,  4,  5, 24, 25, 26, 27, 28, 20, 21, 33, 34, 35, 32, 34, 36, 31,\n",
      "         33, 34, 36, 23, 30, 32, 34, 35, 36, 30, 31, 32, 33, 35, 36, 21, 22, 30,\n",
      "         33, 34, 31, 32, 33, 34]])\n"
     ]
    }
   ],
   "source": [
    "# Look at one graph\n",
    "# 37 nodes. Each node has 3 features.\n",
    "data = dataset[0]\n",
    "print(data)\n",
    "print( data.is_undirected() )\n",
    "print( data.x )\n",
    "print( data.y ) # A 1x1 matrix, i.e. 'y' is just a single value\n",
    "print(data.edge_index)\n",
    "\n",
    "# Shuffle the dataset\n",
    "dataset = dataset.shuffle()\n",
    "\n",
    "# Example of splitting dataset (training/testing)\n",
    "train_dataset = dataset[:540]\n",
    "test_dataset = dataset[540:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "572de825-6bd1-48f0-bbfa-25e6485b208f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now try Cora dataset\n",
    "from torch_geometric.datasets import Planetoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "15314321-e0e1-4404-bc75-77e4d4b2fe10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cora()\n",
      "Data(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This dataset is just one large graph.\n",
    "# One learns on it by using \"masks\" i.e. subsets of the graph.\n",
    "dataset = Planetoid(root='/tmp/Cora', name='Cora')\n",
    "# >>> Cora()\n",
    "len(dataset)\n",
    "# >>> 1\n",
    "dataset.num_classes\n",
    "# >>> 7\n",
    "dataset.num_node_features\n",
    "# >>> 1433\n",
    "\n",
    "# \"Here, the dataset contains only a *single*, undirected citation graph:\"\n",
    "print(dataset)\n",
    "data = dataset[0]\n",
    "print(data)\n",
    "# >>> Data(edge_index=[2, 10556], test_mask=[2708],\n",
    "#          train_mask=[2708], val_mask=[2708], x=[2708, 1433], y=[2708])\n",
    "\n",
    "'''\n",
    "train_mask denotes against which nodes to train (140 nodes),\n",
    "val_mask denotes which nodes to use for validation, e.g., to perform early stopping (500 nodes),\n",
    "test_mask denotes against which nodes to test (1000 nodes).\n",
    "'''\n",
    "\n",
    "data.is_undirected()\n",
    "# >>> True\n",
    "data.train_mask.sum().item()\n",
    "# >>> 140\n",
    "data.val_mask.sum().item()\n",
    "# >>> 500\n",
    "data.test_mask.sum().item()\n",
    "# >>> 1000\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e5f17b-abe4-4e98-b77d-5a95180a67f2",
   "metadata": {},
   "source": [
    "## Mini-batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5fe0c2a9-2166-447c-b235-9887bf51f0f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataBatch(edge_index=[2, 3816], x=[978, 21], y=[32], batch=[978], ptr=[33])\n",
      "32\n",
      "DataBatch(edge_index=[2, 3640], x=[946, 21], y=[32], batch=[946], ptr=[33])\n",
      "32\n",
      "DataBatch(edge_index=[2, 4284], x=[1127, 21], y=[32], batch=[1127], ptr=[33])\n",
      "32\n",
      "DataBatch(edge_index=[2, 4330], x=[1108, 21], y=[32], batch=[1108], ptr=[33])\n",
      "32\n",
      "DataBatch(edge_index=[2, 3720], x=[1005, 21], y=[32], batch=[1005], ptr=[33])\n",
      "32\n",
      "DataBatch(edge_index=[2, 3774], x=[970, 21], y=[32], batch=[970], ptr=[33])\n",
      "32\n",
      "DataBatch(edge_index=[2, 3558], x=[900, 21], y=[32], batch=[900], ptr=[33])\n",
      "32\n",
      "DataBatch(edge_index=[2, 3838], x=[1071, 21], y=[32], batch=[1071], ptr=[33])\n",
      "32\n",
      "DataBatch(edge_index=[2, 4270], x=[1072, 21], y=[32], batch=[1072], ptr=[33])\n",
      "32\n",
      "DataBatch(edge_index=[2, 3866], x=[996, 21], y=[32], batch=[996], ptr=[33])\n",
      "32\n",
      "DataBatch(edge_index=[2, 4374], x=[1149, 21], y=[32], batch=[1149], ptr=[33])\n",
      "32\n",
      "DataBatch(edge_index=[2, 3736], x=[1011, 21], y=[32], batch=[1011], ptr=[33])\n",
      "32\n",
      "DataBatch(edge_index=[2, 4618], x=[1256, 21], y=[32], batch=[1256], ptr=[33])\n",
      "32\n",
      "DataBatch(edge_index=[2, 3902], x=[1022, 21], y=[32], batch=[1022], ptr=[33])\n",
      "32\n",
      "DataBatch(edge_index=[2, 3740], x=[954, 21], y=[32], batch=[954], ptr=[33])\n",
      "32\n",
      "DataBatch(edge_index=[2, 4198], x=[1142, 21], y=[32], batch=[1142], ptr=[33])\n",
      "32\n",
      "DataBatch(edge_index=[2, 3926], x=[1019, 21], y=[32], batch=[1019], ptr=[33])\n",
      "32\n",
      "DataBatch(edge_index=[2, 3776], x=[974, 21], y=[32], batch=[974], ptr=[33])\n",
      "32\n",
      "DataBatch(edge_index=[2, 3198], x=[880, 21], y=[24], batch=[880], ptr=[25])\n",
      "24\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "torch_geometric.data.Batch inherits from torch_geometric.data.Data and contains an additional attribute called batch\n",
    "\n",
    "'batch' is a column vector which maps each node to its respective graph in the batch:\n",
    "'''\n",
    "\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "dataset = TUDataset(root='/tmp/ENZYMES', name='ENZYMES', use_node_attr=True)\n",
    "loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "for batch in loader:\n",
    "    print(batch)\n",
    "    # >>> DataBatch(batch=[1082], edge_index=[2, 4066], x=[1082, 21], y=[32])\n",
    "\n",
    "    print(batch.num_graphs)\n",
    "    # >>> 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8d8a1adc-5528-43f1-afeb-f9062413f9ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataBatch(edge_index=[2, 4550], x=[1199, 21], y=[32], batch=[1199], ptr=[33])\n",
      "32\n",
      "torch.Size([32, 21])\n",
      "DataBatch(edge_index=[2, 3774], x=[974, 21], y=[32], batch=[974], ptr=[33])\n",
      "32\n",
      "torch.Size([32, 21])\n",
      "DataBatch(edge_index=[2, 3342], x=[881, 21], y=[32], batch=[881], ptr=[33])\n",
      "32\n",
      "torch.Size([32, 21])\n",
      "DataBatch(edge_index=[2, 3892], x=[1025, 21], y=[32], batch=[1025], ptr=[33])\n",
      "32\n",
      "torch.Size([32, 21])\n",
      "DataBatch(edge_index=[2, 3808], x=[982, 21], y=[32], batch=[982], ptr=[33])\n",
      "32\n",
      "torch.Size([32, 21])\n",
      "DataBatch(edge_index=[2, 4218], x=[1061, 21], y=[32], batch=[1061], ptr=[33])\n",
      "32\n",
      "torch.Size([32, 21])\n",
      "DataBatch(edge_index=[2, 3416], x=[966, 21], y=[32], batch=[966], ptr=[33])\n",
      "32\n",
      "torch.Size([32, 21])\n",
      "DataBatch(edge_index=[2, 3528], x=[891, 21], y=[32], batch=[891], ptr=[33])\n",
      "32\n",
      "torch.Size([32, 21])\n",
      "DataBatch(edge_index=[2, 4356], x=[1158, 21], y=[32], batch=[1158], ptr=[33])\n",
      "32\n",
      "torch.Size([32, 21])\n",
      "DataBatch(edge_index=[2, 4204], x=[1161, 21], y=[32], batch=[1161], ptr=[33])\n",
      "32\n",
      "torch.Size([32, 21])\n",
      "DataBatch(edge_index=[2, 3930], x=[1057, 21], y=[32], batch=[1057], ptr=[33])\n",
      "32\n",
      "torch.Size([32, 21])\n",
      "DataBatch(edge_index=[2, 4052], x=[1025, 21], y=[32], batch=[1025], ptr=[33])\n",
      "32\n",
      "torch.Size([32, 21])\n",
      "DataBatch(edge_index=[2, 3480], x=[889, 21], y=[32], batch=[889], ptr=[33])\n",
      "32\n",
      "torch.Size([32, 21])\n",
      "DataBatch(edge_index=[2, 4284], x=[1134, 21], y=[32], batch=[1134], ptr=[33])\n",
      "32\n",
      "torch.Size([32, 21])\n",
      "DataBatch(edge_index=[2, 4530], x=[1183, 21], y=[32], batch=[1183], ptr=[33])\n",
      "32\n",
      "torch.Size([32, 21])\n",
      "DataBatch(edge_index=[2, 4540], x=[1163, 21], y=[32], batch=[1163], ptr=[33])\n",
      "32\n",
      "torch.Size([32, 21])\n",
      "DataBatch(edge_index=[2, 3702], x=[953, 21], y=[32], batch=[953], ptr=[33])\n",
      "32\n",
      "torch.Size([32, 21])\n",
      "DataBatch(edge_index=[2, 3836], x=[959, 21], y=[32], batch=[959], ptr=[33])\n",
      "32\n",
      "torch.Size([32, 21])\n",
      "DataBatch(edge_index=[2, 3122], x=[919, 21], y=[24], batch=[919], ptr=[25])\n",
      "24\n",
      "torch.Size([24, 21])\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.utils import scatter\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "dataset = TUDataset(root='/tmp/ENZYMES', name='ENZYMES', use_node_attr=True)\n",
    "loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "for data in loader:\n",
    "    print( data )\n",
    "\n",
    "    print( data.num_graphs )\n",
    "    x = scatter(data.x, data.batch, dim=0, reduce='mean')\n",
    "    print( x.size() )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3fdb63-0a9c-4108-b25d-110c058ebbe3",
   "metadata": {},
   "source": [
    "## Data Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "76a1ee54-4a0b-4a5b-b288-1ccc0b8ae311",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://shapenet.cs.stanford.edu/media/shapenetcore_partanno_segmentation_benchmark_v0_normal.zip\n",
      "Extracting /tmp/ShapeNet/shapenetcore_partanno_segmentation_benchmark_v0_normal.zip\n",
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Data(x=[2518, 3], y=[2518], pos=[2518, 3], category=[1])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 17,000 3D shape point clouds and per point labels from 16 shape categories\n",
    "from torch_geometric.datasets import ShapeNet\n",
    "\n",
    "dataset = ShapeNet(root='/tmp/ShapeNet', categories=['Airplane'])\n",
    "\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "154e0189-4e73-450a-a09a-01b67e338055",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicolassawaya/miniconda3/envs/pando/lib/python3.11/site-packages/torch_geometric/data/dataset.py:214: UserWarning: The `pre_transform` argument differs from the one used in the pre-processed version of this dataset. If you want to make use of another pre-processing technique, make sure to delete '/tmp/ShapeNet/processed' first\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Data(x=[2518, 3], y=[2518], pos=[2518, 3], category=[1])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can convert the point cloud dataset into a graph dataset by generating nearest neighbor graphs from the point clouds via transforms:\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.datasets import ShapeNet\n",
    "\n",
    "dataset = ShapeNet(root='/tmp/ShapeNet', categories=['Airplane'],\n",
    "                    pre_transform=T.KNNGraph(k=6))\n",
    "\n",
    "dataset[0]\n",
    "# Data(edge_index=[2, 15108], pos=[2518, 3], y=[2518])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2930130b-6707-4776-a108-649ed04f92ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In addition, we can use the transform argument to randomly augment a Data object, e.g., translating each node position by a small number:\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.datasets import ShapeNet\n",
    "\n",
    "dataset = ShapeNet(root='/tmp/ShapeNet', categories=['Airplane'],\n",
    "                    pre_transform=T.KNNGraph(k=6),\n",
    "                    transform=T.RandomJitter(0.01))\n",
    "\n",
    "dataset[0]\n",
    ">>> Data(edge_index=[2, 15108], pos=[2518, 3], y=[2518])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b41b69-a1d9-40e1-b1c8-04f24a64da3d",
   "metadata": {},
   "source": [
    "## Learning Methods on Graphs\n",
    "\n",
    "\"After learning about data handling, datasets, loader and transforms in PyG, it’s time to implement our first graph neural network!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e255ed9c-87f7-4091-bf7a-df78dfc2b88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We first need to load the Cora dataset:\n",
    "from torch_geometric.datasets import Planetoid\n",
    "\n",
    "dataset = Planetoid(root='/tmp/Cora', name='Cora')\n",
    "# >>> Cora()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0c97055f-826b-4cce-b9b5-6df2d00b99cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let’s implement a two-layer GCN:\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Two GCN convolution layers\n",
    "        self.conv1 = GCNConv(dataset.num_node_features, 16)\n",
    "        self.conv2 = GCNConv(16, dataset.num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ba510f9c-aa55-43e8-8a9d-39e9efaf186d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = GCN().to(device)\n",
    "data = dataset[0].to(device)  # Again, this is single graph\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(200):\n",
    "    optimizer.zero_grad()  # Reset gradients\n",
    "    out = model(data)\n",
    "    # Negative log likelihood loss. For training classification problem.\n",
    "    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4adc180f-916b-4f8d-ab03-3953f60da782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8050\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "pred = model(data).argmax(dim=1)\n",
    "correct = (pred[data.test_mask] == data.y[data.test_mask]).sum()\n",
    "acc = int(correct) / int(data.test_mask.sum())\n",
    "print(f'Accuracy: {acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "38f44aad-aa07-4d3c-b2d9-9dc4e95082e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test mask\n",
      "tensor([False, False, False,  ...,  True,  True,  True])\n",
      "Predicted\n",
      "tensor([3, 4, 4,  ..., 0, 3, 3])\n",
      "Actual\n",
      "tensor([3, 4, 4,  ..., 3, 3, 3])\n",
      "tensor(805)\n"
     ]
    }
   ],
   "source": [
    "torch.set_printoptions(threshold=100)\n",
    "# Test mask\n",
    "print(\"Test mask\")\n",
    "print( data.test_mask )\n",
    "# Predicted\n",
    "print(\"Predicted\")\n",
    "print( pred )\n",
    "# Actual\n",
    "print(\"Actual\")\n",
    "print( data.y )\n",
    "# \n",
    "print( correct )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d59de8-f860-466e-95af-ea72498465b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bec8c7c-0994-447d-906f-2aa4a45dc3bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ab0bd1-051f-4fc8-bba7-b34b5bb0f9b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df288fd1-99db-40f5-b952-d69e9931b706",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9154b28-14bb-4437-8532-aa0ccc997e01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cca8dc4-073a-4100-96b5-f2d02d4bbf19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8654618-4812-46f5-a5c5-ed7039180f7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20414822-1b1d-44dd-8cc8-858a10dfcdd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f273e227-0b70-4f7c-b996-812f05189082",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2366743a-99d4-48e9-b3fa-bb6ca78db3df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e17ed4-0f24-47c9-9e8c-b3556640af1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011d575b-91de-42ae-9aac-f6b022f8e274",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85381bb-3920-40eb-a619-5147b137b606",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b85d21-6097-47d0-bb66-1cbca938d432",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4694dfe1-8082-44ad-8d0a-790fb829f881",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49973689-79d9-4bd7-a933-40e6c84b4a38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e45e73-5c07-4094-a7b2-d07646d30b20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5db080-c60a-44ed-b7c1-04da0e2aa5ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a64236-115b-421e-b0b4-e3d97188beac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
